{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE ENGINEERING PIPELINE\n",
      "======================================================================\n",
      "✅ Loaded price  (1381, 55)\n",
      "✅ Returns matrix: (1380, 55)\n",
      "Date range: 2020-05-28 to 2025-11-21\n",
      "Total trading days: 1,381\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Engineering Pipeline\n",
    "Create comprehensive features for HRP, Black-Litterman, and RL models\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Create directories if needed\n",
    "(project_root / 'data/processed').mkdir(parents=True, exist_ok=True)\n",
    "(project_root / 'data/interim').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load price data\n",
    "prices = pd.read_csv(project_root / 'data/raw/all_close_prices.csv', \n",
    "                     index_col=0, parse_dates=True)\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE ENGINEERING PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Loaded price  {prices.shape}\")\n",
    "print(f\"✅ Returns matrix: {returns.shape}\")\n",
    "print(f\"Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "print(f\"Total trading days: {len(prices):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 1: Multi-Period Returns\n",
      "======================================================================\n",
      "Calculating multi-period returns for each asset...\n",
      "  Processed 10/55 assets\n",
      "  Processed 20/55 assets\n",
      "  Processed 30/55 assets\n",
      "  Processed 40/55 assets\n",
      "  Processed 50/55 assets\n",
      "\n",
      "✅ Return features generated: (1381, 220)\n",
      "   Features per asset: 4 (1d, 5d, 20d, 60d returns)\n",
      "   Total return features: 220\n",
      "\n",
      "Sample features (first asset, last 5 rows):\n",
      "            AAPL_ret_1d  AAPL_ret_5d  AAPL_ret_20d  AAPL_ret_60d\n",
      "date                                                            \n",
      "2025-11-17    -0.018171    -0.007312      0.020894      0.175445\n",
      "2025-11-18    -0.000075    -0.028374      0.018759      0.178461\n",
      "2025-11-19     0.004188    -0.017954      0.040125      0.172301\n",
      "2025-11-20    -0.008601    -0.024547      0.026690      0.156268\n",
      "2025-11-21     0.019681    -0.003377      0.033990      0.168529\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate returns at multiple time horizons\n",
    "\"\"\"\n",
    "\n",
    "def calculate_multiperiod_returns(prices):\n",
    "    \"\"\"\n",
    "    Calculate returns at 1d, 5d, 20d, 60d horizons\n",
    "    These capture different momentum time scales\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=prices.index)\n",
    "    \n",
    "    print(\"Calculating multi-period returns for each asset...\")\n",
    "    for i, ticker in enumerate(prices.columns, 1):\n",
    "        # 1-day returns (daily)\n",
    "        features[f'{ticker}_ret_1d'] = prices[ticker].pct_change(1)\n",
    "        \n",
    "        # 5-day returns (weekly momentum)\n",
    "        features[f'{ticker}_ret_5d'] = prices[ticker].pct_change(5)\n",
    "        \n",
    "        # 20-day returns (monthly momentum)\n",
    "        features[f'{ticker}_ret_20d'] = prices[ticker].pct_change(20)\n",
    "        \n",
    "        # 60-day returns (quarterly momentum)\n",
    "        features[f'{ticker}_ret_60d'] = prices[ticker].pct_change(60)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed {i}/{len(prices.columns)} assets\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: Multi-Period Returns\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "return_features = calculate_multiperiod_returns(prices)\n",
    "\n",
    "print(f\"\\n✅ Return features generated: {return_features.shape}\")\n",
    "print(f\"   Features per asset: 4 (1d, 5d, 20d, 60d returns)\")\n",
    "print(f\"   Total return features: {return_features.shape[1]}\")\n",
    "print(f\"\\nSample features (first asset, last 5 rows):\")\n",
    "asset = prices.columns[0]\n",
    "print(return_features[[f'{asset}_ret_1d', f'{asset}_ret_5d', \n",
    "                       f'{asset}_ret_20d', f'{asset}_ret_60d']].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: Rolling Volatilities\n",
      "======================================================================\n",
      "Calculating rolling volatilities...\n",
      "  Processed 10/55 assets\n",
      "  Processed 20/55 assets\n",
      "  Processed 30/55 assets\n",
      "  Processed 40/55 assets\n",
      "  Processed 50/55 assets\n",
      "\n",
      "✅ Volatility features generated: (1380, 220)\n",
      "   Features per asset: 4 (vol_20d, vol_60d, volvol, vol_ratio)\n",
      "   Total volatility features: 220\n",
      "\n",
      "Sample volatility statistics:\n",
      "  Mean 20-day vol: 27.15%\n",
      "  Mean 60-day vol: 27.92%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate rolling volatilities at different windows\n",
    "\"\"\"\n",
    "\n",
    "def calculate_rolling_volatilities(returns):\n",
    "    \"\"\"\n",
    "    Calculate rolling volatilities (annualized)\n",
    "    20-day: Short-term volatility regime\n",
    "    60-day: Medium-term volatility trend\n",
    "    vol-of-vol: Volatility regime change indicator\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    print(\"Calculating rolling volatilities...\")\n",
    "    for i, ticker in enumerate(returns.columns, 1):\n",
    "        # 20-day volatility (annualized)\n",
    "        vol_20 = returns[ticker].rolling(window=20).std() * np.sqrt(252)\n",
    "        features[f'{ticker}_vol_20d'] = vol_20\n",
    "        \n",
    "        # 60-day volatility (annualized)\n",
    "        vol_60 = returns[ticker].rolling(window=60).std() * np.sqrt(252)\n",
    "        features[f'{ticker}_vol_60d'] = vol_60\n",
    "        \n",
    "        # Volatility of volatility (regime change indicator)\n",
    "        features[f'{ticker}_volvol_20d'] = vol_20.rolling(window=20).std()\n",
    "        \n",
    "        # Volatility ratio (short-term vs long-term)\n",
    "        features[f'{ticker}_vol_ratio'] = vol_20 / vol_60\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed {i}/{len(returns.columns)} assets\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: Rolling Volatilities\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "volatility_features = calculate_rolling_volatilities(returns)\n",
    "\n",
    "print(f\"\\n✅ Volatility features generated: {volatility_features.shape}\")\n",
    "print(f\"   Features per asset: 4 (vol_20d, vol_60d, volvol, vol_ratio)\")\n",
    "print(f\"   Total volatility features: {volatility_features.shape[1]}\")\n",
    "print(f\"\\nSample volatility statistics:\")\n",
    "print(f\"  Mean 20-day vol: {volatility_features.filter(like='_vol_20d').mean().mean():.2%}\")\n",
    "print(f\"  Mean 60-day vol: {volatility_features.filter(like='_vol_60d').mean().mean():.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: Technical Indicators\n",
      "======================================================================\n",
      "Calculating technical indicators...\n",
      "  Processed 10/55 assets\n",
      "  Processed 20/55 assets\n",
      "  Processed 30/55 assets\n",
      "  Processed 40/55 assets\n",
      "  Processed 50/55 assets\n",
      "\n",
      "✅ Technical features generated: (1381, 715)\n",
      "   Features per asset: 14 (RSI, MACD, momentum, MA ratios, BB)\n",
      "   Total technical features: 715\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate technical indicators: RSI, MACD, Momentum, MA ratios\n",
    "\"\"\"\n",
    "\n",
    "def calculate_rsi(prices, period=14):\n",
    "    \"\"\"Relative Strength Index\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / (loss + 1e-10)  # Avoid division by zero\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Moving Average Convergence Divergence\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = prices.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    macd_signal = macd.ewm(span=signal, adjust=False).mean()\n",
    "    macd_hist = macd - macd_signal\n",
    "    return macd, macd_signal, macd_hist\n",
    "\n",
    "def calculate_momentum(prices, period=10):\n",
    "    \"\"\"Price momentum (rate of change)\"\"\"\n",
    "    return prices.diff(period) / prices.shift(period)\n",
    "\n",
    "def calculate_technical_indicators(prices):\n",
    "    \"\"\"Calculate all technical indicators\"\"\"\n",
    "    features = pd.DataFrame(index=prices.index)\n",
    "    \n",
    "    print(\"Calculating technical indicators...\")\n",
    "    for i, ticker in enumerate(prices.columns, 1):\n",
    "        price_series = prices[ticker]\n",
    "        \n",
    "        # RSI (14-period)\n",
    "        features[f'{ticker}_rsi_14'] = calculate_rsi(price_series, 14)\n",
    "        \n",
    "        # MACD indicators\n",
    "        macd, macd_signal, macd_hist = calculate_macd(price_series)\n",
    "        features[f'{ticker}_macd'] = macd\n",
    "        features[f'{ticker}_macd_signal'] = macd_signal\n",
    "        features[f'{ticker}_macd_hist'] = macd_hist\n",
    "        \n",
    "        # Momentum at multiple periods\n",
    "        features[f'{ticker}_momentum_10d'] = calculate_momentum(price_series, 10)\n",
    "        features[f'{ticker}_momentum_20d'] = calculate_momentum(price_series, 20)\n",
    "        features[f'{ticker}_momentum_60d'] = calculate_momentum(price_series, 60)\n",
    "        \n",
    "        # Moving average ratios\n",
    "        ma_20 = price_series.rolling(window=20).mean()\n",
    "        ma_50 = price_series.rolling(window=50).mean()\n",
    "        ma_200 = price_series.rolling(window=200).mean()\n",
    "        \n",
    "        features[f'{ticker}_price_to_ma20'] = price_series / ma_20\n",
    "        features[f'{ticker}_price_to_ma50'] = price_series / ma_50\n",
    "        features[f'{ticker}_price_to_ma200'] = price_series / ma_200\n",
    "        features[f'{ticker}_ma20_to_ma50'] = ma_20 / ma_50\n",
    "        features[f'{ticker}_ma50_to_ma200'] = ma_50 / ma_200\n",
    "        \n",
    "        # Bollinger Bands position\n",
    "        bb_std = price_series.rolling(window=20).std()\n",
    "        bb_upper = ma_20 + (2 * bb_std)\n",
    "        bb_lower = ma_20 - (2 * bb_std)\n",
    "        features[f'{ticker}_bb_position'] = (price_series - bb_lower) / (bb_upper - bb_lower + 1e-10)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed {i}/{len(prices.columns)} assets\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: Technical Indicators\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "technical_features = calculate_technical_indicators(prices)\n",
    "\n",
    "print(f\"\\n✅ Technical features generated: {technical_features.shape}\")\n",
    "print(f\"   Features per asset: 14 (RSI, MACD, momentum, MA ratios, BB)\")\n",
    "print(f\"   Total technical features: {technical_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: Correlation Features\n",
      "======================================================================\n",
      "Calculating rolling correlations (window=60 days)...\n",
      "Market proxy: SPY\n",
      "  Processed 10/55 assets\n",
      "  Processed 20/55 assets\n",
      "  Processed 30/55 assets\n",
      "  Processed 40/55 assets\n",
      "  Processed 50/55 assets\n",
      "\n",
      "✅ Correlation features generated: (1380, 165)\n",
      "   Features per asset: 3 (market corr, avg corr, vol corr)\n",
      "   Total correlation features: 165\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate rolling correlation features\n",
    "\"\"\"\n",
    "\n",
    "def calculate_rolling_correlations(returns, window=60):\n",
    "    \"\"\"\n",
    "    Calculate rolling correlations:\n",
    "    - Correlation with market (SPY)\n",
    "    - Average correlation with sector peers\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    # Market proxy (use SPY if available, otherwise first ticker)\n",
    "    market_ticker = 'SPY' if 'SPY' in returns.columns else returns.columns[0]\n",
    "    market_returns = returns[market_ticker]\n",
    "    \n",
    "    print(f\"Calculating rolling correlations (window={window} days)...\")\n",
    "    print(f\"Market proxy: {market_ticker}\")\n",
    "    \n",
    "    for i, ticker in enumerate(returns.columns, 1):\n",
    "        # Correlation with market\n",
    "        features[f'{ticker}_corr_market_{window}d'] = \\\n",
    "            returns[ticker].rolling(window=window).corr(market_returns)\n",
    "        \n",
    "        # Average correlation with all other assets (computational shortcut: use 10 assets)\n",
    "        other_assets = [col for col in returns.columns if col != ticker][:10]\n",
    "        rolling_corrs = []\n",
    "        \n",
    "        for other in other_assets:\n",
    "            corr = returns[ticker].rolling(window=window).corr(returns[other])\n",
    "            rolling_corrs.append(corr)\n",
    "        \n",
    "        if rolling_corrs:\n",
    "            features[f'{ticker}_avg_corr_{window}d'] = \\\n",
    "                pd.concat(rolling_corrs, axis=1).mean(axis=1)\n",
    "        \n",
    "        # Rolling correlation with volatility (regime indicator)\n",
    "        ticker_vol = returns[ticker].rolling(window=20).std()\n",
    "        market_vol = market_returns.rolling(window=20).std()\n",
    "        features[f'{ticker}_vol_corr_market_{window}d'] = \\\n",
    "            ticker_vol.rolling(window=window).corr(market_vol)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed {i}/{len(returns.columns)} assets\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: Correlation Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "correlation_features = calculate_rolling_correlations(returns, window=60)\n",
    "\n",
    "print(f\"\\n✅ Correlation features generated: {correlation_features.shape}\")\n",
    "print(f\"   Features per asset: 3 (market corr, avg corr, vol corr)\")\n",
    "print(f\"   Total correlation features: {correlation_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: Risk Metrics\n",
      "======================================================================\n",
      "Calculating risk metrics...\n",
      "  Processed 10/55 assets\n",
      "  Processed 20/55 assets\n",
      "  Processed 30/55 assets\n",
      "  Processed 40/55 assets\n",
      "  Processed 50/55 assets\n",
      "\n",
      "✅ Risk features generated: (1380, 275)\n",
      "   Features per asset: 5 (drawdown, max_dd, VaR, CVaR, downside_dev)\n",
      "   Total risk features: 275\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate advanced risk metrics\n",
    "\"\"\"\n",
    "\n",
    "def calculate_risk_metrics(returns, prices):\n",
    "    \"\"\"\n",
    "    Calculate risk metrics:\n",
    "    - Drawdown\n",
    "    - Value at Risk (VaR)\n",
    "    - Conditional VaR (CVaR/Expected Shortfall)\n",
    "    - Downside deviation\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    print(\"Calculating risk metrics...\")\n",
    "    for i, ticker in enumerate(returns.columns, 1):\n",
    "        ticker_returns = returns[ticker]\n",
    "        ticker_prices = prices[ticker]\n",
    "        \n",
    "        # Running maximum and drawdown\n",
    "        running_max = ticker_prices.expanding().max()\n",
    "        drawdown = (ticker_prices - running_max) / running_max\n",
    "        features[f'{ticker}_drawdown'] = drawdown\n",
    "        \n",
    "        # Rolling max drawdown (60-day)\n",
    "        rolling_dd = ticker_returns.rolling(window=60).apply(\n",
    "            lambda x: ((1 + x).cumprod() / (1 + x).cumprod().cummax() - 1).min(),\n",
    "            raw=False\n",
    "        )\n",
    "        features[f'{ticker}_max_dd_60d'] = rolling_dd\n",
    "        \n",
    "        # Value at Risk (95% confidence, 60-day rolling)\n",
    "        features[f'{ticker}_var_95_60d'] = \\\n",
    "            ticker_returns.rolling(window=60).quantile(0.05)\n",
    "        \n",
    "        # Conditional VaR (Expected Shortfall, 60-day rolling)\n",
    "        def cvar_95(x):\n",
    "            if len(x) < 5:\n",
    "                return np.nan\n",
    "            var_95 = x.quantile(0.05)\n",
    "            tail_losses = x[x <= var_95]\n",
    "            return tail_losses.mean() if len(tail_losses) > 0 else var_95\n",
    "        \n",
    "        features[f'{ticker}_cvar_95_60d'] = \\\n",
    "            ticker_returns.rolling(window=60).apply(cvar_95, raw=False)\n",
    "        \n",
    "        # Downside deviation (relative to 0% return)\n",
    "        def downside_dev(x):\n",
    "            negative_returns = x[x < 0]\n",
    "            if len(negative_returns) == 0:\n",
    "                return 0\n",
    "            return np.sqrt((negative_returns ** 2).mean())\n",
    "        \n",
    "        features[f'{ticker}_downside_dev_60d'] = \\\n",
    "            ticker_returns.rolling(window=60).apply(downside_dev, raw=False)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processed {i}/{len(returns.columns)} assets\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: Risk Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "risk_features = calculate_risk_metrics(returns, prices)\n",
    "\n",
    "print(f\"\\n✅ Risk features generated: {risk_features.shape}\")\n",
    "print(f\"   Features per asset: 5 (drawdown, max_dd, VaR, CVaR, downside_dev)\")\n",
    "print(f\"   Total risk features: {risk_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: Market-Wide Features\n",
      "======================================================================\n",
      "Calculating market-wide features...\n",
      "  Calculating rolling average correlations (this may take a moment)...\n",
      "✅ Market features: 10 features\n",
      "\n",
      "✅ Market features generated: (1380, 10)\n",
      "   Features: 10 (market vol, momentum, breadth, etc.)\n",
      "\n",
      "Sample market features (last 5 rows):\n",
      "            market_vol_20d  market_ret_20d  breadth_20d  avg_market_corr_60d\n",
      "date                                                                        \n",
      "2025-11-17        0.130677       -0.008387     0.454545             0.163118\n",
      "2025-11-18        0.133711       -0.016699     0.490909             0.153652\n",
      "2025-11-19        0.133633       -0.007742     0.490909             0.150301\n",
      "2025-11-20        0.141338       -0.028626     0.400000             0.148342\n",
      "2025-11-21        0.143079       -0.026903     0.381818             0.153373\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate market-wide features (same for all assets)\n",
    "\"\"\"\n",
    "\n",
    "def calculate_market_features(returns, prices):\n",
    "    \"\"\"\n",
    "    Calculate market-level features that apply to all assets:\n",
    "    - Market volatility regime\n",
    "    - Market momentum\n",
    "    - Dispersion (cross-sectional volatility)\n",
    "    - Breadth indicators\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    print(\"Calculating market-wide features...\")\n",
    "    \n",
    "    # Market proxy (SPY or equal-weighted)\n",
    "    if 'SPY' in returns.columns:\n",
    "        market_returns = returns['SPY']\n",
    "        market_prices = prices['SPY']\n",
    "    else:\n",
    "        market_returns = returns.mean(axis=1)\n",
    "        market_prices = (prices / prices.iloc[0]).mean(axis=1) * 100\n",
    "    \n",
    "    # Market volatility (VIX proxy)\n",
    "    features['market_vol_20d'] = market_returns.rolling(window=20).std() * np.sqrt(252)\n",
    "    features['market_vol_60d'] = market_returns.rolling(window=60).std() * np.sqrt(252)\n",
    "    \n",
    "    # Market momentum\n",
    "    features['market_ret_20d'] = market_prices.pct_change(20)\n",
    "    features['market_ret_60d'] = market_prices.pct_change(60)\n",
    "    \n",
    "    # Cross-sectional dispersion (market regime indicator)\n",
    "    features['dispersion_20d'] = returns.rolling(window=20).std().mean(axis=1)\n",
    "    \n",
    "    # Market breadth (% of stocks with positive returns)\n",
    "    features['breadth_1d'] = (returns > 0).sum(axis=1) / len(returns.columns)\n",
    "    features['breadth_20d'] = (returns.rolling(window=20).sum() > 0).sum(axis=1) / len(returns.columns)\n",
    "    \n",
    "    # Average correlation (market regime) - simplified calculation\n",
    "    print(\"  Calculating rolling average correlations (this may take a moment)...\")\n",
    "    corr_values = []\n",
    "    for i in range(len(returns)):\n",
    "        if i < 60:\n",
    "            corr_values.append(np.nan)\n",
    "        else:\n",
    "            window_returns = returns.iloc[i-60:i]\n",
    "            corr = window_returns.corr().values\n",
    "            avg_corr = corr[np.triu_indices_from(corr, k=1)].mean()\n",
    "            corr_values.append(avg_corr)\n",
    "    \n",
    "    features['avg_market_corr_60d'] = corr_values\n",
    "    \n",
    "    # Advance/Decline ratio\n",
    "    advances = (returns > 0).sum(axis=1)\n",
    "    declines = (returns < 0).sum(axis=1)\n",
    "    features['advance_decline_ratio'] = advances / (declines + 1)\n",
    "    \n",
    "    # Market trend (above/below 200-day MA)\n",
    "    ma_200 = market_prices.rolling(window=200).mean()\n",
    "    features['market_trend_200d'] = (market_prices > ma_200).astype(int)\n",
    "    \n",
    "    print(f\"✅ Market features: {features.shape[1]} features\")\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: Market-Wide Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "market_features = calculate_market_features(returns, prices)\n",
    "\n",
    "print(f\"\\n✅ Market features generated: {market_features.shape}\")\n",
    "print(f\"   Features: {market_features.shape[1]} (market vol, momentum, breadth, etc.)\")\n",
    "print(f\"\\nSample market features (last 5 rows):\")\n",
    "display_cols = ['market_vol_20d', 'market_ret_20d', 'breadth_20d', 'avg_market_corr_60d']\n",
    "print(market_features[display_cols].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: Combining All Features\n",
      "======================================================================\n",
      "\n",
      "Combined feature matrix: (1381, 1605)\n",
      "  1,605 total features\n",
      "  1,381 time periods\n",
      "\n",
      "Missing value statistics:\n",
      "  Features with >50% missing: 0\n",
      "  Features with >20% missing: 0\n",
      "  Features with >10% missing: 110\n",
      "\n",
      "Before dropping NaN: 1381 rows\n",
      "After dropping NaN: 1182 rows\n",
      "Rows dropped: 199\n",
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "======================================================================\n",
      "Return features:          220\n",
      "Volatility features:      220\n",
      "Technical features:       715\n",
      "Correlation features:     165\n",
      "Risk features:            275\n",
      "Market features:           10\n",
      "----------------------------------------------------------------------\n",
      "TOTAL FEATURES:         1,605\n",
      "\n",
      "Clean dataset:\n",
      "  Date range: 2021-03-12 to 2025-11-21\n",
      "  Trading days: 1,182\n",
      "  Assets: 55\n",
      "  Features per asset: ~29\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Combine all feature sets into master feature matrix\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 7: Combining All Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine all features\n",
    "all_features = pd.concat([\n",
    "    return_features,\n",
    "    volatility_features,\n",
    "    technical_features,\n",
    "    correlation_features,\n",
    "    risk_features,\n",
    "    market_features\n",
    "], axis=1)\n",
    "\n",
    "print(f\"\\nCombined feature matrix: {all_features.shape}\")\n",
    "print(f\"  {all_features.shape[1]:,} total features\")\n",
    "print(f\"  {all_features.shape[0]:,} time periods\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_pct = (all_features.isnull().sum() / len(all_features) * 100).sort_values(ascending=False)\n",
    "print(f\"\\nMissing value statistics:\")\n",
    "print(f\"  Features with >50% missing: {(missing_pct > 50).sum()}\")\n",
    "print(f\"  Features with >20% missing: {(missing_pct > 20).sum()}\")\n",
    "print(f\"  Features with >10% missing: {(missing_pct > 10).sum()}\")\n",
    "\n",
    "# Drop initial rows with NaN (due to 200-day MA and other long windows)\n",
    "print(f\"\\nBefore dropping NaN: {all_features.shape[0]} rows\")\n",
    "all_features_clean = all_features.dropna()\n",
    "print(f\"After dropping NaN: {all_features_clean.shape[0]} rows\")\n",
    "print(f\"Rows dropped: {all_features.shape[0] - all_features_clean.shape[0]}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Return features:       {return_features.shape[1]:>6,}\")\n",
    "print(f\"Volatility features:   {volatility_features.shape[1]:>6,}\")\n",
    "print(f\"Technical features:    {technical_features.shape[1]:>6,}\")\n",
    "print(f\"Correlation features:  {correlation_features.shape[1]:>6,}\")\n",
    "print(f\"Risk features:         {risk_features.shape[1]:>6,}\")\n",
    "print(f\"Market features:       {market_features.shape[1]:>6,}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"TOTAL FEATURES:        {all_features_clean.shape[1]:>6,}\")\n",
    "print(f\"\\nClean dataset:\")\n",
    "print(f\"  Date range: {all_features_clean.index[0].date()} to {all_features_clean.index[-1].date()}\")\n",
    "print(f\"  Trading days: {len(all_features_clean):,}\")\n",
    "print(f\"  Assets: {len(prices.columns)}\")\n",
    "print(f\"  Features per asset: ~{all_features_clean.shape[1] // len(prices.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 8: Saving Features\n",
      "======================================================================\n",
      "✅ Saved full feature matrix: /Users/aryamansingh/Desktop/adaptive_portfolio_manager/data/processed/all_features.csv\n",
      "   Size: 36.0 MB\n",
      "✅ Saved return_features.csv: (1321, 220)\n",
      "✅ Saved volatility_features.csv: (1321, 220)\n",
      "✅ Saved technical_features.csv: (1182, 715)\n",
      "✅ Saved correlation_features.csv: (1302, 165)\n",
      "✅ Saved risk_features.csv: (1321, 275)\n",
      "✅ Saved market_features.csv: (1320, 10)\n",
      "\n",
      "✅ Saved clean prices and returns\n",
      "   Prices: (1182, 55)\n",
      "   Returns: (1182, 55)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save all processed features to disk\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 8: Saving Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save full feature matrix\n",
    "output_path = project_root / 'data/processed/all_features.csv'\n",
    "all_features_clean.to_csv(output_path)\n",
    "print(f\"✅ Saved full feature matrix: {output_path}\")\n",
    "print(f\"   Size: {output_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "# Save individual feature sets\n",
    "feature_sets = {\n",
    "    'return_features.csv': return_features.dropna(),\n",
    "    'volatility_features.csv': volatility_features.dropna(),\n",
    "    'technical_features.csv': technical_features.dropna(),\n",
    "    'correlation_features.csv': correlation_features.dropna(),\n",
    "    'risk_features.csv': risk_features.dropna(),\n",
    "    'market_features.csv': market_features.dropna(),\n",
    "}\n",
    "\n",
    "for filename, df in feature_sets.items():\n",
    "    filepath = project_root / f'data/processed/{filename}'\n",
    "    df.to_csv(filepath)\n",
    "    print(f\"✅ Saved {filename}: {df.shape}\")\n",
    "\n",
    "# Also save clean prices and returns aligned with features\n",
    "prices_clean = prices.loc[all_features_clean.index]\n",
    "returns_clean = returns.loc[all_features_clean.index]\n",
    "\n",
    "prices_clean.to_csv(project_root / 'data/processed/prices_clean.csv')\n",
    "returns_clean.to_csv(project_root / 'data/processed/returns_clean.csv')\n",
    "\n",
    "print(f\"\\n✅ Saved clean prices and returns\")\n",
    "print(f\"   Prices: {prices_clean.shape}\")\n",
    "print(f\"   Returns: {returns_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Feature documentation saved: /Users/aryamansingh/Desktop/adaptive_portfolio_manager/data/processed/FEATURE_DOCUMENTATION.txt\n",
      "✅ Feature summary CSV saved\n",
      "\n",
      "======================================================================\n",
      "03_FEATURE_ENGINEERING.IPYNB COMPLETE\n",
      "======================================================================\n",
      "✅ Generated 1,605 features\n",
      "✅ Clean dataset: 1,182 trading days\n",
      "✅ Saved to data/processed/\n",
      "✅ Documentation created\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create comprehensive feature documentation\n",
    "\"\"\"\n",
    "\n",
    "feature_docs = {\n",
    "    'Return Features (4 per asset)': {\n",
    "        'ret_1d': '1-day (daily) price return',\n",
    "        'ret_5d': '5-day (weekly) price return',\n",
    "        'ret_20d': '20-day (monthly) price return',\n",
    "        'ret_60d': '60-day (quarterly) price return',\n",
    "    },\n",
    "    'Volatility Features (4 per asset)': {\n",
    "        'vol_20d': '20-day rolling volatility (annualized)',\n",
    "        'vol_60d': '60-day rolling volatility (annualized)',\n",
    "        'volvol_20d': 'Volatility of volatility (regime indicator)',\n",
    "        'vol_ratio': 'Ratio of short-term to long-term volatility',\n",
    "    },\n",
    "    'Technical Indicators (14 per asset)': {\n",
    "        'rsi_14': 'Relative Strength Index (14-period)',\n",
    "        'macd': 'MACD line (12-26 EMA difference)',\n",
    "        'macd_signal': 'MACD signal line (9-period EMA of MACD)',\n",
    "        'macd_hist': 'MACD histogram (MACD - Signal)',\n",
    "        'momentum_10d': '10-day price momentum',\n",
    "        'momentum_20d': '20-day price momentum',\n",
    "        'momentum_60d': '60-day price momentum',\n",
    "        'price_to_ma20': 'Price relative to 20-day MA',\n",
    "        'price_to_ma50': 'Price relative to 50-day MA',\n",
    "        'price_to_ma200': 'Price relative to 200-day MA',\n",
    "        'ma20_to_ma50': '20-day MA relative to 50-day MA',\n",
    "        'ma50_to_ma200': '50-day MA relative to 200-day MA',\n",
    "        'bb_position': 'Position within Bollinger Bands (0-1)',\n",
    "    },\n",
    "    'Correlation Features (3 per asset)': {\n",
    "        'corr_market_60d': 'Rolling 60-day correlation with market (SPY)',\n",
    "        'avg_corr_60d': 'Average rolling correlation with other assets',\n",
    "        'vol_corr_market_60d': 'Correlation of volatility with market volatility',\n",
    "    },\n",
    "    'Risk Metrics (5 per asset)': {\n",
    "        'drawdown': 'Current drawdown from peak',\n",
    "        'max_dd_60d': 'Maximum drawdown in last 60 days',\n",
    "        'var_95_60d': 'Value at Risk (95% confidence, 60-day)',\n",
    "        'cvar_95_60d': 'Conditional VaR / Expected Shortfall (95%, 60-day)',\n",
    "        'downside_dev_60d': 'Downside deviation (60-day)',\n",
    "    },\n",
    "    'Market-Wide Features (9 features)': {\n",
    "        'market_vol_20d': 'Market volatility (20-day annualized)',\n",
    "        'market_vol_60d': 'Market volatility (60-day annualized)',\n",
    "        'market_ret_20d': 'Market return (20-day)',\n",
    "        'market_ret_60d': 'Market return (60-day)',\n",
    "        'dispersion_20d': 'Cross-sectional volatility dispersion',\n",
    "        'breadth_1d': 'Daily breadth (% positive returns)',\n",
    "        'breadth_20d': '20-day breadth indicator',\n",
    "        'avg_market_corr_60d': 'Average pairwise correlation (60-day)',\n",
    "        'advance_decline_ratio': 'Ratio of advancing to declining assets',\n",
    "        'market_trend_200d': 'Market above/below 200-day MA (0/1)',\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create documentation file\n",
    "doc_lines = []\n",
    "doc_lines.append(\"=\"*80)\n",
    "doc_lines.append(\"FEATURE ENGINEERING DOCUMENTATION\")\n",
    "doc_lines.append(\"=\"*80)\n",
    "doc_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "doc_lines.append(f\"Project: Adaptive Portfolio Manager with RL\")\n",
    "doc_lines.append(\"\")\n",
    "doc_lines.append(f\"Total Features: {all_features_clean.shape[1]:,}\")\n",
    "doc_lines.append(f\"Total Assets: {len(prices.columns)}\")\n",
    "doc_lines.append(f\"Date Range: {all_features_clean.index[0].date()} to {all_features_clean.index[-1].date()}\")\n",
    "doc_lines.append(f\"Trading Days: {len(all_features_clean):,}\")\n",
    "doc_lines.append(\"\")\n",
    "\n",
    "for category, features in feature_docs.items():\n",
    "    doc_lines.append(f\"\\n{category}:\")\n",
    "    doc_lines.append(\"-\" * 80)\n",
    "    for feature, description in features.items():\n",
    "        doc_lines.append(f\"  {feature:.<35} {description}\")\n",
    "\n",
    "doc_lines.append(\"\\n\" + \"=\"*80)\n",
    "doc_lines.append(\"USAGE NOTES\")\n",
    "doc_lines.append(\"=\"*80)\n",
    "doc_lines.append(\"\"\"\n",
    "1. All features are already calculated and aligned by date\n",
    "2. Features require 200+ days of history (due to 200-day MA)\n",
    "3. Missing values have been dropped - clean dataset ready for modeling\n",
    "4. Asset-specific features are prefixed with ticker symbol\n",
    "5. Market-wide features apply to all assets (no prefix)\n",
    "\n",
    "For HRP/Black-Litterman:\n",
    "  - Use return features (ret_20d, ret_60d)\n",
    "  - Use volatility features (vol_20d, vol_60d)\n",
    "  - Use correlation features\n",
    "\n",
    "For Reinforcement Learning:\n",
    "  - Use all features as state space\n",
    "  - Normalize features before training\n",
    "  - Consider PCA for dimensionality reduction if needed\n",
    "\"\"\")\n",
    "\n",
    "# Save documentation\n",
    "doc_path = project_root / 'data/processed/FEATURE_DOCUMENTATION.txt'\n",
    "with open(doc_path, 'w') as f:\n",
    "    f.write('\\n'.join(doc_lines))\n",
    "\n",
    "print(f\"\\n✅ Feature documentation saved: {doc_path}\")\n",
    "\n",
    "# Also create a feature summary CSV\n",
    "feature_summary = []\n",
    "for category, features in feature_docs.items():\n",
    "    for feature, description in features.items():\n",
    "        feature_summary.append({\n",
    "            'Category': category,\n",
    "            'Feature_Pattern': feature,\n",
    "            'Description': description\n",
    "        })\n",
    "\n",
    "feature_summary_df = pd.DataFrame(feature_summary)\n",
    "feature_summary_df.to_csv(project_root / 'data/processed/feature_summary.csv', index=False)\n",
    "print(f\"✅ Feature summary CSV saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"03_FEATURE_ENGINEERING.IPYNB COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Generated {all_features_clean.shape[1]:,} features\")\n",
    "print(f\"✅ Clean dataset: {len(all_features_clean):,} trading days\")\n",
    "print(f\"✅ Saved to data/processed/\")\n",
    "print(f\"✅ Documentation created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
